{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Column 22 (Rpt_Block_Num) is almost all int except for when they put 111 1/2 or 111 BLK\n",
    "rpt_block_num_cnvtr = lambda x: x.split(' ')[0] if len(x.split(' ')) > 1 and x.split(' ')[1] in ['1/2', 'BLK'] else x\n",
    "rpt_sec_hwy_sfx_dict = {'W': 22, 'R': 17, 'E': 5, 'S': 18, 'N': 14, 'M': 13, 'A': 1}\n",
    "rpt_sec_hwy_sfx_cnvtr = lambda x: rpt_sec_hwy_sfx_dict[x] if type(x) == str and len(x) > 0 else x\n",
    "crash_10_cnvtr = {22: rpt_block_num_cnvtr}\n",
    "crash_12_cnvtr = {22: rpt_block_num_cnvtr, 35: rpt_sec_hwy_sfx_cnvtr, 20: rpt_sec_hwy_sfx_cnvtr}\n",
    "dtypes = {'Rpt_Sec_Hwy_Num': str, 'Rpt_Sec_Block_Num': str, 'Street_Nbr': str, \\\n",
    "          'Rpt_CrossingNumber': str, 'Rpt_CrossingNumber': str, 'CrossingNumber': str, 'RRCo': str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# crash_10 skipped rows have data split incorrectly in csv file starting at col 33\n",
    "# crash_15, 16, 17 skipped rows have Rpt_Hwy_Sfx values entered incorrectly \n",
    "#     (entered actual sfx rather than data dict code)\n",
    "crash_10 = pd.read_csv('data/2010/extract_public_2010_20170913160331_crash_20100101-20101231_TRAVIS.csv', \\\n",
    "                       converters=crash_10_cnvtr, skiprows=[2495, 3258, 3580, 8252, 9523], dtype=dtypes, \\\n",
    "                       index_col='Crash_ID')\n",
    "crash_11 = pd.read_csv('data/2011/extract_public_2010_20170913151637_crash_20110101-20111231_TRAVIS.csv', \\\n",
    "                      converters=crash_10_cnvtr, dtype=dtypes, index_col='Crash_ID')\n",
    "crash_12 = pd.read_csv('data/2012/extract_public_2010_20170913151619_crash_20120101-20121231_TRAVIS.csv', \\\n",
    "                      converters=crash_12_cnvtr, dtype=dtypes, index_col='Crash_ID')\n",
    "crash_13 = pd.read_csv('data/2013/extract_public_2010_20170913151600_crash_20130101-20131231_TRAVIS.csv', \\\n",
    "                      dtype=dtypes, index_col='Crash_ID')\n",
    "crash_14 = pd.read_csv('data/2014/extract_public_2010_20170913151542_crash_20140101-20141231_TRAVIS.csv', \\\n",
    "                       dtype=dtypes, index_col='Crash_ID')\n",
    "crash_15 = pd.read_csv('data/2015/extract_public_2015_20170829153840_crash_20150101-20151231_TRAVIS.csv', \\\n",
    "                       converters=crash_12_cnvtr, dtype=dtypes, index_col='Crash_ID', \\\n",
    "                       skiprows=[5177, 5446, 6653, 9839, 9841, 14381, 19176])\n",
    "crash_16 = pd.read_csv('data/2016/extract_public_2015_20170829153815_crash_20160101-20161231_TRAVIS.csv', \\\n",
    "                       converters=crash_12_cnvtr, dtype=dtypes, skiprows=[2432, 3794, 3795, 8077, 8188, 20173], \\\n",
    "                       index_col='Crash_ID')\n",
    "crash_17 = pd.read_csv('data/2017/extract_public_2015_20170829132341_crash_20170101-20170829_TRAVIS.csv', \\\n",
    "                      converters=crash_12_cnvtr, dtype=dtypes, skiprows=[4480], index_col='Crash_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crash = pd.concat([crash_10, crash_11, crash_12, crash_13, crash_14, crash_15, crash_16, crash_17])\n",
    "crash['Crash_Timestamp'] = crash['Crash_Date'] + ' ' + crash['Crash_Time']\n",
    "crash['Crash_Timestamp'] = pd.to_datetime(crash['Crash_Timestamp'])\n",
    "crash = crash.drop(['Crash_Date', 'Crash_Time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking no new duplicates from concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crash[crash.Crash_ID.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "damages_10 = pd.read_csv('data/2010/extract_public_2010_20170913160331_damages_20100101-20101231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "damages_11 = pd.read_csv('data/2011/extract_public_2010_20170913151637_damages_20110101-20111231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "damages_12 = pd.read_csv('data/2012/extract_public_2010_20170913151619_damages_20120101-20121231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "damages_13 = pd.read_csv('data/2013/extract_public_2010_20170913151600_damages_20130101-20131231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "damages_14 = pd.read_csv('data/2014/extract_public_2010_20170913151542_damages_20140101-20141231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "damages_15 = pd.read_csv('data/2015/extract_public_2015_20170829153840_damages_20150101-20151231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "damages_16 = pd.read_csv('data/2016/extract_public_2015_20170829153815_damages_20160101-20161231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "damages_17 = pd.read_csv('data/2017/extract_public_2015_20170829132341_damages_20170101-20170829_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "damages = pd.concat([damages_10, damages_11, damages_12, damages_13, damages_14, damages_15, damages_16, damages_17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking no new duplicates from concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# damages['dup'] = damages['Crash_ID'].map(str) + damages['Damaged_Property'].map(str)\n",
    "# damages = damages.sort_values(by='dup')\n",
    "# duplicates shown exist in csv. must be 'multiple counts of damages' or something like that\n",
    "# damages[damages['dup'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmv_carrier_zip_cnvtr = lambda x: x.replace('-', '') if '-' in str(x) else x\n",
    "unit_10_cnvtr = {31: cmv_carrier_zip_cnvtr}\n",
    "dtypes = {80: str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Unit_16 skipped rows had column values shifted in the csv\n",
    "unit_10 = pd.read_csv('data/2010/extract_public_2010_20170913160331_unit_20100101-20101231_TRAVIS.csv', \\\n",
    "                     converters=unit_10_cnvtr, index_col='Crash_ID')\n",
    "unit_11 = pd.read_csv('data/2011/extract_public_2010_20170913151637_unit_20110101-20111231_TRAVIS.csv', \\\n",
    "                      index_col='Crash_ID')\n",
    "unit_12 = pd.read_csv('data/2012/extract_public_2010_20170913151619_unit_20120101-20121231_TRAVIS.csv', \\\n",
    "                      index_col='Crash_ID')\n",
    "unit_13 = pd.read_csv('data/2013/extract_public_2010_20170913151600_unit_20130101-20131231_TRAVIS.csv', \\\n",
    "                      index_col='Crash_ID')\n",
    "unit_14 = pd.read_csv('data/2014/extract_public_2010_20170913151542_unit_20140101-20141231_TRAVIS.csv', \\\n",
    "                      index_col='Crash_ID')\n",
    "unit_15 = pd.read_csv('data/2015/extract_public_2015_20170829153840_unit_20150101-20151231_TRAVIS.csv', \\\n",
    "                      index_col='Crash_ID')\n",
    "unit_16 = pd.read_csv('data/2016/extract_public_2015_20170829153815_unit_20160101-20161231_TRAVIS.csv', \\\n",
    "                     skiprows=[43205], dtype=dtypes, index_col='Crash_ID')\n",
    "unit_17 = pd.read_csv('data/2017/extract_public_2015_20170829132341_unit_20170101-20170829_TRAVIS.csv', \\\n",
    "                      index_col='Crash_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit = pd.concat([unit_10, unit_11, unit_12, unit_13, unit_14, unit_15, unit_16, unit_17])\n",
    "unit = unit.drop(['Incap_Injry_Cnt', 'Nonincap_Injry_Cnt', 'Poss_Injry_Cnt', 'Non_Injry_Cnt', \\\n",
    "                        'Unkn_Injry_Cnt', 'Tot_Injry_Cnt', 'Death_Cnt'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking no new duplicates from concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unit['dup'] = unit['Crash_ID'].map(str) + unit['Unit_Nbr'].map(str)\n",
    "# unit = unit.sort_values(by='dup')\n",
    "# unit[unit['dup'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PrimaryPerson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "primaryperson_10 = pd.read_csv('data/2010/extract_public_2010_20170913160331_primaryperson_20100101-20101231_TRAVIS.csv', \\\n",
    "                               index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "primaryperson_11 = pd.read_csv('data/2011/extract_public_2010_20170913151637_primaryperson_20110101-20111231_TRAVIS.csv', \\\n",
    "                               index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "primaryperson_12 = pd.read_csv('data/2012/extract_public_2010_20170913151619_primaryperson_20120101-20121231_TRAVIS.csv', \\\n",
    "                               index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "primaryperson_13 = pd.read_csv('data/2013/extract_public_2010_20170913151600_primaryperson_20130101-20131231_TRAVIS.csv', \\\n",
    "                               index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "primaryperson_14 = pd.read_csv('data/2014/extract_public_2010_20170913151542_primaryperson_20140101-20141231_TRAVIS.csv', \\\n",
    "                               index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "primaryperson_15 = pd.read_csv('data/2015/extract_public_2015_20170829153840_primaryperson_20150101-20151231_TRAVIS.csv', \\\n",
    "                               index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "primaryperson_16 = pd.read_csv('data/2016/extract_public_2015_20170829153815_primaryperson_20160101-20161231_TRAVIS.csv', \\\n",
    "                               index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "primaryperson_17 = pd.read_csv('data/2017/extract_public_2015_20170829132341_primaryperson_20170101-20170829_TRAVIS.csv', \\\n",
    "                               index_col=['Crash_ID', 'Unit_Nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "primaryperson = pd.concat([primaryperson_10, primaryperson_11, primaryperson_12, primaryperson_13, primaryperson_14, primaryperson_15, primaryperson_16, primaryperson_17])\n",
    "primaryperson = primaryperson.drop(['Incap_Injry_Cnt', 'Nonincap_Injry_Cnt', 'Poss_Injry_Cnt', 'Non_Injry_Cnt', \\\n",
    "                        'Unkn_Injry_Cnt', 'Tot_Injry_Cnt', 'Death_Cnt'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking no new duplicates from concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# primaryperson['dup'] = primaryperson['Crash_ID'].map(str) + primaryperson['Unit_Nbr'].map(str) + primaryperson['Prsn_Nbr'].map(str)\n",
    "# primaryperson = primaryperson.sort_values(by='dup')\n",
    "# primaryperson[primaryperson['dup'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person_10 = pd.read_csv('data/2010/extract_public_2010_20170913160331_person_20100101-20101231_TRAVIS.csv', \\\n",
    "                        index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "person_11 = pd.read_csv('data/2011/extract_public_2010_20170913151637_person_20110101-20111231_TRAVIS.csv', \\\n",
    "                        index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "person_12 = pd.read_csv('data/2012/extract_public_2010_20170913151619_person_20120101-20121231_TRAVIS.csv', \\\n",
    "                        index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "person_13 = pd.read_csv('data/2013/extract_public_2010_20170913151600_person_20130101-20131231_TRAVIS.csv', \\\n",
    "                        index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "person_14 = pd.read_csv('data/2014/extract_public_2010_20170913151542_person_20140101-20141231_TRAVIS.csv', \\\n",
    "                        index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "person_15 = pd.read_csv('data/2015/extract_public_2015_20170829153840_person_20150101-20151231_TRAVIS.csv', \\\n",
    "                        index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "person_16 = pd.read_csv('data/2016/extract_public_2015_20170829153815_person_20160101-20161231_TRAVIS.csv', \\\n",
    "                        index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "person_17 = pd.read_csv('data/2017/extract_public_2015_20170829132341_person_20170101-20170829_TRAVIS.csv', \\\n",
    "                        index_col=['Crash_ID', 'Unit_Nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person = pd.concat([person_10, person_11, person_12, person_13, person_14, person_15, person_16, person_17])\n",
    "person = person.drop(['Incap_Injry_Cnt', 'Nonincap_Injry_Cnt', 'Poss_Injry_Cnt', 'Non_Injry_Cnt', \\\n",
    "                        'Unkn_Injry_Cnt', 'Tot_Injry_Cnt', 'Death_Cnt'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking no new duplicates from concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# person['dup'] = person['Crash_ID'].map(str) + person['Unit_Nbr'].map(str) + person['Prsn_Nbr'].map(str)\n",
    "# person = person.sort_values(by='dup')\n",
    "# person[person['dup'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Endorsements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endorsements_10 = pd.read_csv('data/2010/extract_public_2010_20170913160331_endorsements_20100101-20101231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "endorsements_11 = pd.read_csv('data/2011/extract_public_2010_20170913151637_endorsements_20110101-20111231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "endorsements_12 = pd.read_csv('data/2012/extract_public_2010_20170913151619_endorsements_20120101-20121231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "endorsements_13 = pd.read_csv('data/2013/extract_public_2010_20170913151600_endorsements_20130101-20131231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "endorsements_14 = pd.read_csv('data/2014/extract_public_2010_20170913151542_endorsements_20140101-20141231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "endorsements_15 = pd.read_csv('data/2015/extract_public_2015_20170829153840_endorsements_20150101-20151231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "endorsements_16 = pd.read_csv('data/2016/extract_public_2015_20170829153815_endorsements_20160101-20161231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "endorsements_17 = pd.read_csv('data/2017/extract_public_2015_20170829132341_endorsements_20170101-20170829_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endorsements = pd.concat([endorsements_10, endorsements_11, endorsements_12, endorsements_13, endorsements_14, endorsements_15, endorsements_16, endorsements_17])\n",
    "endorsements['Prsn_Nbr'] = 1.0\n",
    "endorsements = endorsements.reset_index().set_index(['Crash_ID', 'Unit_Nbr', 'Prsn_Nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking no new duplicates from concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# endorsements['dup'] = endorsements['Crash_ID'].map(str) + endorsements['Unit_Nbr'].map(str) + endorsements['Drvr_Lic_Endors_ID'].map(str)\n",
    "# endorsements = endorsements.sort_values(by='dup')\n",
    "# endorsements[endorsements['dup'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restrictions_10 = pd.read_csv('data/2010/extract_public_2010_20170913160331_restrictions_20100101-20101231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "restrictions_11 = pd.read_csv('data/2011/extract_public_2010_20170913151637_restrictions_20110101-20111231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "restrictions_12 = pd.read_csv('data/2012/extract_public_2010_20170913151619_restrictions_20120101-20121231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "restrictions_13 = pd.read_csv('data/2013/extract_public_2010_20170913151600_restrictions_20130101-20131231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "restrictions_14 = pd.read_csv('data/2014/extract_public_2010_20170913151542_restrictions_20140101-20141231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "restrictions_15 = pd.read_csv('data/2015/extract_public_2015_20170829153840_restrictions_20150101-20151231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "restrictions_16 = pd.read_csv('data/2016/extract_public_2015_20170829153815_restrictions_20160101-20161231_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])\n",
    "restrictions_17 = pd.read_csv('data/2017/extract_public_2015_20170829132341_restrictions_20170101-20170829_TRAVIS.csv', \\\n",
    "                              index_col=['Crash_ID', 'Unit_Nbr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restrictions = pd.concat([restrictions_10, restrictions_11, restrictions_12, restrictions_13, restrictions_14, restrictions_15, restrictions_16, restrictions_17])\n",
    "restrictions['Prsn_Nbr'] = 1.0\n",
    "restrictions = restrictions.reset_index().set_index(['Crash_ID', 'Unit_Nbr', 'Prsn_Nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking no new duplicates from concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# restrictions['dup'] = restrictions['Crash_ID'].map(str) + restrictions['Unit_Nbr'].map(str) + restrictions['Drvr_Lic_Restric_ID'].map(str)\n",
    "# restrictions = restrictions.sort_values(by='dup')\n",
    "# restrictions[restrictions['dup'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "charges_10 = pd.read_csv('data/2010/extract_public_2010_20170913160331_charges_20100101-20101231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "charges_11 = pd.read_csv('data/2011/extract_public_2010_20170913151637_charges_20110101-20111231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "charges_12 = pd.read_csv('data/2012/extract_public_2010_20170913151619_charges_20120101-20121231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "charges_13 = pd.read_csv('data/2013/extract_public_2010_20170913151600_charges_20130101-20131231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "charges_14 = pd.read_csv('data/2014/extract_public_2010_20170913151542_charges_20140101-20141231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "charges_15 = pd.read_csv('data/2015/extract_public_2015_20170829153840_charges_20150101-20151231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "charges_16 = pd.read_csv('data/2016/extract_public_2015_20170829153815_charges_20160101-20161231_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')\n",
    "charges_17 = pd.read_csv('data/2017/extract_public_2015_20170829132341_charges_20170101-20170829_TRAVIS.csv', \\\n",
    "                         index_col='Crash_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "charges = pd.concat([charges_10, charges_11, charges_12, charges_13, charges_14, charges_15, charges_16, charges_17])\n",
    "charges = charges.reset_index().set_index(['Crash_ID', 'Unit_Nbr', 'Prsn_Nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking no new duplicates from concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# charges['dup'] = charges.Crash_ID.map(str) + charges.Unit_Nbr.map(str) + charges.Prsn_Nbr.map(str) + charges.Charge_Cat_ID.map(str) + charges.Charge + charges.Citation_Nbr.map(str)\n",
    "# charges = charges.sort_values(by='dup')\n",
    "# charges[charges.dup.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining each section of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined = crash.join(damages, how='left')\n",
    "joined = joined.join(unit, how='left')\n",
    "joined = joined.reset_index().set_index(['Crash_ID', 'Unit_Nbr'])\n",
    "\n",
    "people = pd.concat([person, primaryperson])\n",
    "people = people.sort_index()\n",
    "joined = joined.join(people, how='left')\n",
    "joined = joined.reset_index().set_index(['Crash_ID', 'Unit_Nbr', 'Prsn_Nbr'])\n",
    "joined = joined.sort_index()\n",
    "joined = joined.join(endorsements, how='left')\n",
    "joined = joined.join(restrictions, how='left')\n",
    "joined = joined.join(charges, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
